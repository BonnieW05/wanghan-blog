---
title: v-jepa2éƒ¨åˆ†è·‘é€šç»éªŒ
date: 2025-07-15T22:47:00+08:00
draft: false
tags:
  - æŠ€æœ¯ç¬”è®°
  - ä¸–ç•Œæ¨¡å‹
categories:
  - æŠ€æœ¯ç¬”è®°
description:
cover:
  image: ""
  alt: ""
  caption: ""
  relative: false
---
# vjepaä»£ç éƒ¨åˆ†è·‘é€šç»éªŒ

ç§Ÿçš„ä¾ç„¶æ˜¯autodlä¸ŠRTX4090/24G, æœåŠ¡å™¨ç§Ÿèµç›¸å…³è§ä¸Šç¯‡


## ç¯å¢ƒé…ç½®

åœ¨cloneä¸‹æ¥çš„ä¸»ç›®å½•ä¸‹è¿è¡Œ

```

conda create -n vjepa2-312 python=3.12

conda activate vjepa2-312

pip install .

```

  

## è·‘é€šdemo

### notebooks/vjepa2_demo.ipynb â€”â€” for mac

ä¸€å¼€å§‹æ˜¯åœ¨macä¸Šåšçš„å°è¯•ï¼Œæ‰€ä»¥è¿™é‡Œæä¾›ä¸€ä¸‹åœ¨macä¸ŠæˆåŠŸè¿è¡Œvjepa2_demo.ipynbæ‰€éœ€çš„æ”¹åŠ¨ï¼ˆæŠŠcudaç›¸å…³çš„æ”¹æ‰ï¼Œç„¶åæŠŠæ²¡åŠæ³•è¿æ¥åˆ°çš„èµ„æºæ¢ä¸ªæºï¼‰ã€‚ä»¥åŠå‡ºäºå¯¹é…ç½®çš„è€ƒè™‘å°†giantç›¸å…³çš„ä»£ç æ”¹æˆäº†largeç›¸å…³ä»£ç 

  

1. å°†decordæ¢æˆopencv

å°†from decord import VideoReaderæ¢æˆimport cv2

åœ¨ç¬¬ä¸€ä¸ªå—ä¸­

```python

if os.getcwd().endswith('notebooks'):

os.chdir('..') # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•

```

å°†åŸå…ˆçš„get_video()ç”¨ä»¥ä¸‹å‡½æ•°æ›¿ä»£

```python

def get_video():

cap = cv2.VideoCapture("sample_video.mp4")

total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

frames = []

frame_idx = np.arange(0, min(128, total_frames), 2)

current_frame = 0

while True:

ret, frame = cap.read()

if not ret:

break

if current_frame in frame_idx:

frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

frame_tensor = torch.tensor(frame_rgb, dtype=torch.uint8) # ä½¿ç”¨ torch.tensor() ä»£æ›¿ torch.from_numpy()

frames.append(frame_tensor)

current_frame += 1

if len(frames) >= len(frame_idx):

break

cap.release()

video = torch.stack(frames, dim=0)

return video

```

  

2. giantè½¬large

å°†from src.models.vision_transformer import vit_giant_xformers_ropeæ¢æˆfrom src.models.vision_transformer import vit_large_rope

ä»¥åŠåœ¨loadæ¨¡å‹çš„æ—¶å€™å˜æˆhf_model_name = "facebook/vjepa2-vitl-fpc64-256"

  

3. å…³äºæ¢æº

å› ä¸ºåœ¨æœ¬æœºä¸Šä¸€ç›´è¿ä¸ä¸Šhugging face, æ‰€ä»¥åšäº†ä»¥ä¸‹æ›¿æ¢ã€‚ä½†å¦‚æœæ˜¯åœ¨autodlæœåŠ¡å™¨ä¸Šè·‘çš„è¯ï¼Œå¯ä»¥é‡‡ç”¨ç§‘ç ”ç›¸å…³åŠ é€Ÿæ¥è§£å†³ã€‚è¯¦æƒ…è§å…¶æ–‡æ¡£ã€‚

åœ¨å‘½ä»¤è¡Œè¿è¡Œexport HF_ENDPOINT=https://hf-mirror.com

å°†forward_vjepa_video()ç”¨ä»¥ä¸‹å‡½æ•°æ›¿ä»£

```python

def forward_vjepa_video(model_hf, model_pt, hf_transform, pt_transform):

with torch.inference_mode():

video = get_video()

if video.dtype == torch.uint8:

video = video.float() / 255.0

video = video.permute(0, 3, 1, 2)

x_pt = pt_transform(video).unsqueeze(0)

x_hf = x_pt

out_patch_features_pt = model_pt(x_pt)

out_patch_features_hf = model_pt(x_hf)

return out_patch_features_hf, out_patch_features_pt

```

æ¨¡å‹åŠ è½½æ¨¡å—å˜æˆ

```python

# HuggingFace model repo name

hf_model_name = "facebook/vjepa2-vitl-fpc64-256"

# Path to local PyTorch weights

pt_model_path = "./models/vitl.pt"

  

try:

model_hf = AutoModel.from_pretrained(hf_model_name, trust_remote_code=True)

hf_transform = AutoVideoProcessor.from_pretrained(hf_model_name, trust_remote_code=True)

img_size = hf_transform.crop_size["height"]

model_hf.eval()

print("âœ… HuggingFace åŠ è½½æˆåŠŸ")

except:

print("âš ï¸ HuggingFace å¤±è´¥ï¼Œä½¿ç”¨ PyTorch ç‰ˆæœ¬")

img_size = 256 # ä»æ¨¡å‹åæ¨æ–­

model_pt = vit_large_rope(img_size=(img_size, img_size), num_frames=64)

model_pt.eval()

load_pretrained_vjepa_pt_weights(model_pt, pt_model_path)

model_hf = model_pt

class SimpleTransform:

crop_size = {"height": img_size}

hf_transform = SimpleTransform()

  

if 'model_pt' not in locals():

model_pt = model_hf

  

# Build PyTorch preprocessing transform

pt_video_transform = build_pt_video_transform(img_size=img_size)

```

  

æœ€åè¿è¡Œèµ·æ¥æ•ˆæœbelike:

![alt text](0bd94464f353ac52f9384167e8686a1.png)

:)

  

### vjepa2_demo.py â€”â€” for networkless(

ç”±äºä¸€å¼€å§‹æˆ‘å®åœ¨æœ¬æœºwslä¸Šè·‘çš„ï¼Œè¿™ä¸ªéƒ¨åˆ†çš„å¾ˆå¤šä¸œè¥¿ä¸€ç›´è¿ä¸ä¸Šï¼Œæ‰€ä»¥ç›´æ¥é‡‡ç”¨äº†æš´åŠ›ä¸‹è½½ + ä¸Šä¼  + ç›´æ¥åœ¨æœ¬åœ°loadçš„æ–¹æ³• X æ‰€ä»¥å¦‚æœèƒ½è¿ä¸Šçš„è¯å¤§æ¦‚ä¸ç”¨è¿™ä¹ˆéº»çƒ¦

å…·ä½“æ¥è¯´ï¼š

1. èµ„æºè·å–

ç›´æ¥åœ¨æµè§ˆå™¨è¾“å…¥ https://dl.fbaipublicfiles.com/vjepa2/vitg-384.ptå’Œhttps://dl.fbaipublicfiles.com/vjepa2/evals/ssv2-vitg-384-64x2x3.pt ä¸‹è½½äº†æ–‡ä»¶ç„¶åä¸Šä¼ åˆ°äº†æœåŠ¡å™¨ï¼Œå¹¶ç§»åˆ°äº†/root/autodl-tmp/vjepa2_models

ssv2_classes.jsonç›´æ¥ç‚¹å‡» https://huggingface.co/datasets/huggingface/label-files/resolve/d79675f2d50a7b1ecf98923d42c30526a51818e2/ ç„¶åæŠŠå†…å®¹å¤åˆ¶åˆ°äº†æœ¬åœ°/root/autodl-tmp/ssv2_classes.jsonæ–‡ä»¶ä¸­

ç„¶åè§†é¢‘ä¹Ÿæ˜¯ç›´æ¥ä» https://huggingface.co/datasets/nateraw/kinetics-mini/resolve/main/val/bowling/-WH-lxmGJVY_000005_000015.mp4 ä¸Šæçš„å¹¶æ”¹åsample_video.mp4

  

2. ä¿®æ”¹è·¯å¾„

pt_model_path = "./vitg-384.pt"

classifier_model_path = "./ssv2-vitg-384-64x2x3.pt"

sample_video_path = "./sample_video.mp4"

ssv2_classes_path = "./ssv2_classes.json"

  

3. ä¿®æ”¹ä»£ç 

```python

# hf_model_name = (

# "facebook/vjepa2-vitg-fpc64-384" # Replace with your favored model, e.g. facebook/vjepa2-vitg-fpc64-384

# )

  

# # Initialize the HuggingFace model, load pretrained weights

# model_hf = AutoModel.from_pretrained(hf_model_name)

# model_hf.cuda().eval()

  

# # Build HuggingFace preprocessing transform

# hf_transform = AutoVideoProcessor.from_pretrained(hf_model_name)

# img_size = hf_transform.crop_size["height"] # E.g. 384, 256, etc.

  

# Inference on video

# out_patch_features_hf, out_patch_features_pt = forward_vjepa_video(

# model_hf, model_pt, hf_transform, pt_video_transform

# )

  

# print(

# f"""

# Inference results on video:

# HuggingFace output shape: {out_patch_features_hf.shape}

# PyTorch output shape: {out_patch_features_pt.shape}

# Absolute difference sum: {torch.abs(out_patch_features_pt - out_patch_features_hf).sum():.6f}

# Close: {torch.allclose(out_patch_features_pt, out_patch_features_hf, atol=1e-3, rtol=1e-3)}

# """

# )

  

with torch.inference_mode():

video = get_video() # T x H x W x C

video = torch.from_numpy(video).permute(0, 3, 1, 2) # T x C x H x W

x_pt = pt_video_transform(video).cuda().unsqueeze(0)

out_patch_features_pt = model_pt(x_pt)

  

print(f"PyTorch output shape: {out_patch_features_pt.shape}")

```

ç„¶ååº”è¯¥å°±èƒ½è·‘é€šå•¦

  

## è·‘é€ševaluation

æˆ‘è·‘çš„æ˜¯ssv2çš„è¯„ä¼°ï¼Œä¸»è¦è§£å†³äº†å‡ ä¸ªéš¾é¢˜ï¼šæ•°æ®é›†ä¸‹è½½ä¸å¤„ç†ï¼Œé…ç½®ä¿®æ”¹ä¸æ¨¡å‹è½¬æ¢ã€‚ä¸‹é¢å°†åˆ†ç‚¹æè¿°

  

### æ•°æ®é›†ç›¸å…³

something something v2æ•°æ®é›†å¯ä»¥åœ¨ https://www.qualcomm.com/developer/software/something-something-v-2-dataset/downloads ä¸‹è½½åˆ°

å…¶ä¸­ä¸¤ä¸ªzipæ–‡ä»¶éƒ½ä¸‹è½½åï¼Œè¿›å…¥å­˜æ”¾å®ƒä»¬çš„ç›®å½•ï¼Œä½¿ç”¨ cat 20bn-something-something-v2-?? | tar zx æŒ‡ä»¤è¿›è¡Œè§£å‹ï¼Œä¼šå¾—åˆ°ä¸€ä¸ªå·¨å¤§çš„20bn-something-something-v2ç›®å½•ï¼Œé‡Œé¢å°±æ˜¯è§†é¢‘æ–‡ä»¶ã€‚

ï¼ˆä¸¤ç‚¹æ³¨æ„ï¼šé¦–å…ˆï¼Œè¿™ä¸¤ä¸ªæ–‡ä»¶å¿…é¡»ä¸€èµ·è§£å‹ï¼Œåªæœ‰ç¬¬ä¸€ä¸ªï¼Œä¼šæç¤ºå¥‡æ€ªçš„EOF; åªæœ‰ç¬¬äºŒä¸ªä¼šæ— æ³•å¼€å§‹ã€‚ å…¶æ¬¡ï¼Œå¦‚æœæ˜¯ä½¿ç”¨autodläº‘æœåŠ¡å™¨çš„è¯ï¼Œè¿™æ—¶å€™å°±åº”è¯¥è€ƒè™‘å…ˆæ‰©å®¹ä¸€ä¸‹æ•°æ®ç›˜ï¼Œç„¶åå¼„å®Œä¹‹ååˆ æ‰è§£å‹å‰æ–‡ä»¶å†ç¼©å®¹å³å¯ã€‚æˆ‘æ˜¯ä¸­é—´æ‰©å®¹äº†20Gï¼Œå¤Ÿç”¨ï¼‰

  

#### ä½¿ç”¨è„šæœ¬åˆ›å»ºcsvæ–‡ä»¶

æ³¨æ„åˆ°é…ç½®æ–‡ä»¶é‡Œdataç›¸å…³è¦æ±‚çš„æ˜¯csvæ–‡ä»¶ï¼Œè€Œæˆ‘ä»¬ä¸‹è½½å’Œè§£å‹åå¾—åˆ°çš„åªæ˜¯è§†é¢‘æ–‡ä»¶å’Œlabel, å› æ­¤è¿˜éœ€è¦å†åšä¸€ä¸ªå¤„ç†ã€‚

```python

#!/usr/bin/env python3

import os

import json

from pathlib import Path

  

# é…ç½®æ–‡ä»¶è·¯å¾„

data_root = "/root/autodl-tmp/dataset/20bn-something-something-v2"

config_dir = "/root/autodl-tmp/dataset/labels"

output_dir = "/root/autodl-tmp/dataset/csv"

os.makedirs(output_dir, exist_ok=True)

  

def normalize_template(template):

import re

return re.sub(r'\[([^\]]+)\]', r'\1', template)

  

def load_labels_mapping(config_dir):

labels_path = os.path.join(config_dir, "labels.json")

if os.path.exists(labels_path):

with open(labels_path, 'r', encoding='utf-8') as f:

labels_data = json.load(f)

if isinstance(labels_data, dict):

return labels_data

elif isinstance(labels_data, list):

return {label: i for i, label in enumerate(labels_data)}

return {}

  

def create_vjepa_csv(split_name, json_filename, data_root, config_dir, output_dir, label_mapping=None):

json_path = os.path.join(config_dir, json_filename)

if not os.path.exists(json_path):

return None

with open(json_path, 'r', encoding='utf-8') as f:

data = json.load(f)

  

csv_lines = []

for item in data:

video_id = item['id']

video_path = os.path.join(data_root, f"{video_id}.webm")

if not os.path.exists(video_path):

continue

if 'template' in item:

template = item['template']

normalized_template = normalize_template(template)

if label_mapping and normalized_template in label_mapping:

label_num = int(label_mapping[normalized_template])

csv_lines.append(f"{video_path} {label_num}") # è¿™ä¸ªæ ¼å¼æ˜¯æŸ¥çœ‹äº†æ¨¡å‹ä¸­ç›¸å…³å¤„ç†ä»£ç å¾—å‡ºçš„ã€‚å®é™…ä¸Šï¼Œå®ƒæ˜¯æŒ‰åˆ—è¯†åˆ«ã€‚

else:

csv_lines.append(f"{video_path} 0")

  

if not csv_lines:

return None

  

csv_path = os.path.join(output_dir, f"ssv2_{split_name}_vjepa_format.csv")

with open(csv_path, 'w', encoding='utf-8') as f:

f.write('\n'.join(csv_lines))

return csv_path

  

def main():

if not os.path.exists(data_root) or not os.path.exists(config_dir):

return

  

label_mapping = load_labels_mapping(config_dir)

create_vjepa_csv("train", "train.json", data_root, config_dir, output_dir, label_mapping)

create_vjepa_csv("val", "validation.json", data_root, config_dir, output_dir, label_mapping)

create_vjepa_csv("test", "test.json", data_root, config_dir, output_dir, label_mapping)

  

if __name__ == "__main__":

main()

```

è¿™æ ·ï¼Œæˆ‘ä»¬å°±å¾—åˆ°äº†æ‰€éœ€çš„csvæ–‡ä»¶

  

### é…ç½®ä¿®æ”¹

æ‰¾åˆ°/root/autodl-tmp/configs/evalæ–‡ä»¶ï¼Œä¿®æ”¹æ‰€é€‰æ¨¡å‹å¯¹åº”çš„ssv2.yamlæ–‡ä»¶ã€‚æ­¤å¤„ä»¥/root/autodl-tmp/configs/eval/vitl/ssv2.yamlåœ¨æˆ‘é€‰æ‹©ç§Ÿèµçš„æœåŠ¡å™¨ä¸Šçš„ä¿®æ”¹ä¸ºä¾‹

```yaml

folder: /root/autodl-tmp/vjepa2_experiments/ssv2_eval # è¾“å‡ºç›®å½•

mem_per_gpu: 20G

nodes: 1

  

data:

dataset_train: /root/autodl-tmp/dataset/csv/ssv2_train_vjepa_format.csv

dataset_val: /root/autodl-tmp/dataset/csv/ssv2_val_vjepa_format.csv

  

optimization:

batch_size: 1

  

checkpoint: /root/autodl-tmp/vjepa2_models/vjepa_official.pt

```

å¦‚æœæ˜¯giantæ¨¡å‹å…¶å®ä¹Ÿå·®ä¸å¤šã€‚ä¸»è¦å°±æ˜¯è¦æ ¹æ®é…ç½®ä¿¡æ¯è°ƒæ•´ä¸€äº›å‚æ•°ã€‚

  

### æ¨¡å‹è½¬æ¢

ç”±äºgiant-368æ¨¡å‹å¯¹æ˜¾å­˜è¦æ±‚å¤ªé«˜ï¼Œæˆ‘å°†é…ç½®ä¸€é™å†é™éƒ½æ²¡æœ‰èƒ½æˆåŠŸè·‘èµ·æ¥ï¼Œæ‰€ä»¥æˆ‘å¼€å§‹æ€è€ƒè½¬å‘æ›´å°è§„æ¨¡çš„æ¨¡å‹ã€‚ä½†æ˜¯é€šè¿‡ https://dl.fbaipublicfiles.com/vjepa2/vitl.pt æ˜¯è·å–ä¸åˆ°largeæ¨¡å‹çš„ptæ–‡ä»¶çš„ï¼Œè€Œåªèƒ½é€šè¿‡ https://huggingface.co/collections/facebook/v-jepa-2-6841bad8413014e185b497a6 åœ¨hugging faceä¸Šçš„æ–‡ä»¶ï¼Œæ‰€ä»¥å°±åœ¨æ€è€ƒæ€ä¹ˆæ ·å¾—åˆ°ä¸€ä¸ªvitl.ptå¡«è¿›é…ç½®æ–‡ä»¶é‡Œï¼ˆå¦åˆ™çš„è¯è¦æŠŠæ¨¡å‹è°ƒç”¨çš„åœ°æ–¹å…¨éƒ¨æ”¹æ‰ï¼Œå¯èƒ½ä¼šæ¯”è¾ƒéº»çƒ¦ï¼‰

ç¢ç¢å¿µï¼šä¸€å¼€å§‹æˆ‘åªæ˜¯è§‰å¾—ä¹Ÿè®¸å¯ä»¥è¯•è¯•æŠŠhugging faceçš„ä»£ç è½¬æˆptæ–‡ä»¶ï¼Œç„¶åå°±å»æ‰¾aié—®äº†ä¸€ç‰ˆä»£ç ï¼ˆå…¶å®è¿™ä¸¤ä¸ªèƒ½è½¬å€’æ˜¯æ¯”è¾ƒè‡ªç„¶ï¼Œæ¯•ç«Ÿéƒ½æ˜¯æ¨¡å‹è®°å½•ç›¸å…³çš„ï¼Œåªæ˜¯ä¸åŒçš„å½¢å¼ï¼‰ ä½†æ˜¯å½“æˆ‘è¯•å›¾ç›´æ¥ç”¨ç¬¬ä¸€ç‰ˆå¼„å‡ºæ¥çš„ptæ–‡ä»¶è·‘ï¼Œå´å‡ºç°äº†å„ç§å„æ ·çš„æŠ¥é”™ã€‚æˆ‘çœ‹äº†ä¸€ä¸‹æŠ¥é”™ï¼Œå¤§æ¦‚æ˜¯å› ä¸ºæœ‰ä¸€äº›å­—æ®µç¼ºå¤±ï¼Œå°±æƒ³åˆ°å¯èƒ½æ˜¯ptè¿™ç§æ ¼å¼å…¶å®ä¹Ÿä¸æ˜¯å®Œå…¨ç›¸åŒçš„ï¼Œå¤§æ¦‚è¿˜å¾—ç¬¦åˆä¸€å®šçš„è§„èŒƒã€‚æ­£å¥½å…¶å®æ˜¯æœ‰ä¸€ä¸ªèƒ½ä¸‹è½½ä¸‹æ¥ä½†æ˜¯æ²¡ç”¨ä¸Šçš„vitg-384.ptï¼Œæˆ‘å°±æƒ³ï¼šä¹Ÿè®¸å¯ä»¥å†™è„šæœ¬åˆ†æä¸€ä¸‹å®ƒæœ‰ä»€ä¹ˆï¼Œç„¶ååè¿‡æ¥æ„å»ºè‡ªå·±çš„æ–‡ä»¶ã€‚äºæ˜¯å°±æŠŠéœ€æ±‚å‘Šè¯‰äº†aiï¼ˆå¹¶å’Œå®ƒè¿›è¡Œäº†æé™æ‹‰æ‰¯ã€‚ã€‚ã€‚å®ƒæœ‰æ—¶å€™çœŸçš„æ˜¯å¬ä¸æ‡‚äººè¯ğŸ¤¬ï¼‰ ä¸è¿‡ç»å†å‡ ç•ªæ‹‰æ‰¯ï¼Œæˆ‘åˆè‡ªå·±å°æ”¹äº†ä¸€ä¸‹ä¹‹åï¼Œå°±å¾—åˆ°äº†æ­£ç¡®çš„â€œç¿»è¯‘è„šæœ¬â€ï¼Œæœ€åæˆåŠŸæŠŠè¯„ä¼°è·‘èµ·æ¥äº†ã€‚ä»£ç å¦‚ä¸‹ï¼š

  

```python

#!/usr/bin/env python3

"""

V-JEPA æ¨¡å‹ä» Hugging Face ä¸‹è½½ã€è½¬æ¢å’Œä¿å­˜è„šæœ¬ï¼ˆæ”¹è¿›ç‰ˆï¼‰

æ”¯æŒå¤šç§è½¬æ¢æ¨¡å¼ä»¥æ»¡è¶³ä¸åŒéœ€æ±‚

"""

  

import os

import torch

import requests

from pathlib import Path

from huggingface_hub import hf_hub_download, snapshot_download

from transformers import AutoModel, AutoConfig

import json

from collections import OrderedDict

  

def setup_directories():

"""åˆ›å»ºå¿…è¦çš„ç›®å½•"""

dirs = ['models', 'converted_models', 'checkpoints']

for d in dirs:

Path(d).mkdir(exist_ok=True)

return dirs

  

def download_vjepa_from_hf(model_name="facebook/vjepa2-vitl-fpc64-256", local_dir="./models"):

"""

ä» Hugging Face ä¸‹è½½ V-JEPA æ¨¡å‹

"""

print(f"å¼€å§‹ä» Hugging Face ä¸‹è½½ {model_name}...")

try:

# æ–¹æ³•1: ä¸‹è½½æ•´ä¸ªä»“åº“

local_path = snapshot_download(

repo_id=model_name,

local_dir=local_dir,

local_dir_use_symlinks=False

)

print(f"æ¨¡å‹å·²ä¸‹è½½åˆ°: {local_path}")

return local_path

except Exception as e:

print(f"ä¸‹è½½å¤±è´¥: {e}")

  

def remove_module_prefix(state_dict):

"""

ç§»é™¤é”®åä¸­çš„ 'module.' å‰ç¼€

"""

new_state_dict = OrderedDict()

for key, value in state_dict.items():

if key.startswith('module.'):

new_key = key[7:] # ç§»é™¤ 'module.'

else:

new_key = key

new_state_dict[new_key] = value

return new_state_dict

  

def extract_encoder_only(checkpoint):

"""

åªæå–encoderéƒ¨åˆ†

"""

if 'encoder' in checkpoint:

encoder_state = checkpoint['encoder']

return remove_module_prefix(encoder_state)

else:

# å¦‚æœç›´æ¥æ˜¯state_dictæ ¼å¼

return remove_module_prefix(checkpoint)

  

def extract_full_model(checkpoint):

"""

æå–å®Œæ•´æ¨¡å‹ï¼ˆencoder + predictorï¼‰

"""

full_state = OrderedDict()

if 'encoder' in checkpoint:

# æ·»åŠ encoder

encoder_state = remove_module_prefix(checkpoint['encoder'])

for key, value in encoder_state.items():

full_state[f"encoder.{key}"] = value

# æ·»åŠ predictor

if 'predictor' in checkpoint:

predictor_state = remove_module_prefix(checkpoint['predictor'])

for key, value in predictor_state.items():

full_state[f"predictor.{key}"] = value

else:

# å¦‚æœç›´æ¥æ˜¯state_dictæ ¼å¼

full_state = remove_module_prefix(checkpoint)

return full_state

  

def extract_backbone_only(checkpoint):

"""

åªæå–backboneéƒ¨åˆ†ï¼ˆä¸åŒ…å«é¢„æµ‹å¤´ï¼‰

"""

backbone_state = OrderedDict()

if 'encoder' in checkpoint:

encoder_state = remove_module_prefix(checkpoint['encoder'])

for key, value in encoder_state.items():

if key.startswith('backbone.') and not key.startswith('backbone.predictor'):

new_key = key[9:] # ç§»é™¤ 'backbone.'

backbone_state[new_key] = value

else:

# å¦‚æœç›´æ¥æ˜¯state_dictæ ¼å¼

state_dict = remove_module_prefix(checkpoint)

for key, value in state_dict.items():

if not key.startswith('predictor') and not key.startswith('head'):

backbone_state[key] = value

return backbone_state

  

def convert_to_standard_vit(checkpoint):

"""

è½¬æ¢ä¸ºæ ‡å‡†ViTæ ¼å¼

"""

standard_state = OrderedDict()

if 'encoder' in checkpoint:

encoder_state = remove_module_prefix(checkpoint['encoder'])

else:

encoder_state = remove_module_prefix(checkpoint)

# æ˜ å°„é”®ååˆ°æ ‡å‡†ViTæ ¼å¼

key_mapping = {

'backbone.patch_embed.proj.weight': 'patch_embed.projection.weight',

'backbone.patch_embed.proj.bias': 'patch_embed.projection.bias',

'backbone.pos_embed': 'embeddings.position_embeddings',

'backbone.cls_token': 'embeddings.cls_token',

}

for old_key, value in encoder_state.items():

# å¤„ç†ç‰¹æ®Šæ˜ å°„

if old_key in key_mapping:

new_key = key_mapping[old_key]

elif old_key.startswith('backbone.blocks.'):

# è½¬æ¢æ³¨æ„åŠ›å’ŒMLPå±‚

new_key = old_key.replace('backbone.blocks.', 'encoder.layer.')

new_key = new_key.replace('.attn.', '.attention.attention.')

new_key = new_key.replace('.mlp.', '.intermediate.')

elif old_key.startswith('backbone.norm.'):

new_key = old_key.replace('backbone.norm.', 'layernorm.')

else:

new_key = old_key

standard_state[new_key] = value

return standard_state

  

def convert_to_official_format(checkpoint):

"""

è½¬æ¢ä¸ºå®˜æ–¹checkpointæ ¼å¼ï¼Œä¿æŒå®Œæ•´ç»“æ„

"""

official_checkpoint = {}

# å¦‚æœå·²ç»æ˜¯å®˜æ–¹æ ¼å¼ï¼Œç›´æ¥è¿”å›

if 'encoder' in checkpoint and 'predictor' in checkpoint:

print("æ£€æµ‹åˆ°å·²æ˜¯å®˜æ–¹checkpointæ ¼å¼")

return checkpoint

# å¦‚æœæ˜¯å•ä¸€state_dictï¼Œéœ€è¦é‡æ„ä¸ºå®˜æ–¹æ ¼å¼

if isinstance(checkpoint, dict) and 'encoder' not in checkpoint:

print("è½¬æ¢å•ä¸€state_dictä¸ºå®˜æ–¹æ ¼å¼")

# åˆå§‹åŒ–ç»“æ„

encoder_state = OrderedDict()

predictor_state = OrderedDict()

for key, value in checkpoint.items():

if 'predictor' in key or 'mask_token' in key:

# ç¡®ä¿æœ‰module.backboneå‰ç¼€

if not key.startswith('module.backbone.'):

new_key = f'module.backbone.{key}'

else:

new_key = key

predictor_state[new_key] = value

else:

# å…¶ä»–éƒ½å½’ç±»ä¸ºencoder

if not key.startswith('module.backbone.'):

new_key = f'module.backbone.{key}'

else:

new_key = key

encoder_state[new_key] = value

# æ„å»ºå®˜æ–¹æ ¼å¼

official_checkpoint['encoder'] = encoder_state

official_checkpoint['predictor'] = predictor_state

official_checkpoint['target_encoder'] = encoder_state.copy() # target_encoderé€šå¸¸æ˜¯encoderçš„å‰¯æœ¬

# æ·»åŠ è®­ç»ƒç›¸å…³çš„é»˜è®¤å€¼

official_checkpoint['epoch'] = 0

official_checkpoint['loss'] = 0.0

official_checkpoint['batch_size'] = 1

official_checkpoint['world_size'] = 1

official_checkpoint['lr'] = 0.0001

# æ·»åŠ ç©ºçš„ä¼˜åŒ–å™¨å’ŒscalerçŠ¶æ€

official_checkpoint['opt'] = {'state': {}, 'param_groups': []}

official_checkpoint['scaler'] = {

'scale': 1.0,

'growth_factor': 2.0,

'backoff_factor': 0.5,

'growth_interval': 2000,

'_growth_tracker': 0

}

return official_checkpoint

  

def convert_model_format(input_path, output_path, conversion_mode="official_format"):

"""

è½¬æ¢æ¨¡å‹æ ¼å¼

conversion_mode é€‰é¡¹:

- "official_format": è½¬æ¢ä¸ºå®˜æ–¹checkpointæ ¼å¼ï¼ˆæ¨èï¼‰

- "encoder_only": åªæå–encoder

- "full_model": æå–encoder+predictor

- "backbone_only": åªæå–backboneï¼ˆæ— é¢„æµ‹å¤´ï¼‰

- "standard_vit": è½¬æ¢ä¸ºæ ‡å‡†ViTæ ¼å¼

- "raw": ä¿æŒåŸå§‹æ ¼å¼ï¼Œåªå»é™¤moduleå‰ç¼€

"""

print(f"å¼€å§‹è½¬æ¢æ¨¡å‹æ ¼å¼ï¼Œæ¨¡å¼: {conversion_mode}")

try:

# æ£€æŸ¥è¾“å…¥è·¯å¾„

if os.path.isdir(input_path):

# å¦‚æœæ˜¯ç›®å½•ï¼Œå¯»æ‰¾æ¨¡å‹æ–‡ä»¶

possible_files = [

"pytorch_model.bin",

"model.safetensors",

"vitl.pt",

"checkpoint.pth"

]

model_file = None

for f in possible_files:

full_path = os.path.join(input_path, f)

if os.path.exists(full_path):

model_file = full_path

break

if not model_file:

raise FileNotFoundError("åœ¨ç›®å½•ä¸­æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")

else:

model_file = input_path

print(f"åŠ è½½æ¨¡å‹æ–‡ä»¶: {model_file}")

# åŠ è½½æ¨¡å‹

if model_file.endswith('.safetensors'):

from safetensors.torch import load_file

checkpoint = load_file(model_file)

else:

checkpoint = torch.load(model_file, map_location='cpu')

print(f"åŸå§‹æ£€æŸ¥ç‚¹åŒ…å« {len(checkpoint)} ä¸ªé¡¶å±‚é”®")

if isinstance(checkpoint, dict):

print(f"é¡¶å±‚é”®: {list(checkpoint.keys())}")

# æ ¹æ®è½¬æ¢æ¨¡å¼å¤„ç†

if conversion_mode == "official_format":

# è½¬æ¢ä¸ºå®˜æ–¹æ ¼å¼

final_checkpoint = convert_to_official_format(checkpoint)

elif conversion_mode == "encoder_only":

final_checkpoint = extract_encoder_only(checkpoint)

elif conversion_mode == "full_model":

final_checkpoint = extract_full_model(checkpoint)

elif conversion_mode == "backbone_only":

final_checkpoint = extract_backbone_only(checkpoint)

elif conversion_mode == "standard_vit":

final_checkpoint = convert_to_standard_vit(checkpoint)

elif conversion_mode == "raw":

if 'encoder' in checkpoint:

final_checkpoint = remove_module_prefix(checkpoint['encoder'])

else:

final_checkpoint = remove_module_prefix(checkpoint)

else:

raise ValueError(f"ä¸æ”¯æŒçš„è½¬æ¢æ¨¡å¼: {conversion_mode}")

# åˆ›å»ºè¾“å‡ºç›®å½•

Path(output_path).mkdir(exist_ok=True)

# ä¿å­˜è½¬æ¢åçš„æ¨¡å‹

if conversion_mode == "official_format":

output_file = os.path.join(output_path, 'vjepa_official.pt')

else:

output_file = os.path.join(output_path, f'vjepa_{conversion_mode}.pt')

torch.save(final_checkpoint, output_file)

print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {output_file}")

# ä¿å­˜æ¨¡å‹ä¿¡æ¯

if conversion_mode == "official_format":

# å¯¹äºå®˜æ–¹æ ¼å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†ç»“æ„ä¿¡æ¯

info = {

'original_file': model_file,

'converted_file': output_file,

'conversion_mode': conversion_mode,

'checkpoint_structure': {

'top_level_keys': list(final_checkpoint.keys()),

'encoder_tensors': len(final_checkpoint['encoder']) if 'encoder' in final_checkpoint else 0,

'predictor_tensors': len(final_checkpoint['predictor']) if 'predictor' in final_checkpoint else 0,

'target_encoder_tensors': len(final_checkpoint['target_encoder']) if 'target_encoder' in final_checkpoint else 0

},

'encoder_keys_sample': list(final_checkpoint['encoder'].keys())[:5] if 'encoder' in final_checkpoint else [],

'predictor_keys_sample': list(final_checkpoint['predictor'].keys())[:5] if 'predictor' in final_checkpoint else []

}

else:

# å…¶ä»–æ ¼å¼çš„æ ‡å‡†ä¿¡æ¯

if isinstance(final_checkpoint, dict):

num_params = sum(p.numel() for p in final_checkpoint.values() if torch.is_tensor(p))

num_tensors = len([v for v in final_checkpoint.values() if torch.is_tensor(v)])

sample_keys = [k for k, v in final_checkpoint.items() if torch.is_tensor(v)][:10]

else:

num_params = 0

num_tensors = 0

sample_keys = []

info = {

'original_file': model_file,

'converted_file': output_file,

'conversion_mode': conversion_mode,

'num_parameters': num_params,

'num_tensors': num_tensors,

'model_keys_sample': sample_keys

}

info_file = os.path.join(output_path, f'model_info_{conversion_mode}.json')

with open(info_file, 'w', encoding='utf-8') as f:

json.dump(info, f, indent=2, ensure_ascii=False)

print(f"æ¨¡å‹ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_file}")

# æ˜¾ç¤ºè½¬æ¢ç»“æœæ‘˜è¦

if conversion_mode == "official_format":

print(f"\nâœ… è½¬æ¢ä¸ºå®˜æ–¹æ ¼å¼æˆåŠŸ!")

print(f" é¡¶å±‚é”®: {list(final_checkpoint.keys())}")

if 'encoder' in final_checkpoint:

print(f" encoder: {len(final_checkpoint['encoder'])} ä¸ªå¼ é‡")

if 'predictor' in final_checkpoint:

print(f" predictor: {len(final_checkpoint['predictor'])} ä¸ªå¼ é‡")

else:

print(f"è½¬æ¢ååŒ…å« {len(final_checkpoint)} ä¸ªå¼ é‡" if isinstance(final_checkpoint, dict) else "è½¬æ¢å®Œæˆ")

return output_file

except Exception as e:

print(f"è½¬æ¢å¤±è´¥: {e}")

import traceback

traceback.print_exc()

return None

  

def verify_model(model_path):

"""

éªŒè¯è½¬æ¢åçš„æ¨¡å‹

"""

print(f"\néªŒè¯æ¨¡å‹: {model_path}")

try:

# åŠ è½½æ¨¡å‹å¹¶æ£€æŸ¥

checkpoint = torch.load(model_path, map_location='cpu')

# æ£€æŸ¥æ˜¯å¦ä¸ºå®˜æ–¹checkpointæ ¼å¼

if isinstance(checkpoint, dict) and 'encoder' in checkpoint:

print("âœ“ æ£€æµ‹åˆ°å®˜æ–¹checkpointæ ¼å¼")

print(f" é¡¶å±‚é”®: {list(checkpoint.keys())}")

if 'encoder' in checkpoint:

encoder_keys = len(checkpoint['encoder'])

print(f" encoder: {encoder_keys} ä¸ªå¼ é‡")

# æ˜¾ç¤ºencoderçš„ç¤ºä¾‹é”®å

sample_keys = list(checkpoint['encoder'].keys())[:3]

for key in sample_keys:

tensor = checkpoint['encoder'][key]

print(f" {key}: {tensor.shape}")

if 'predictor' in checkpoint:

predictor_keys = len(checkpoint['predictor'])

print(f" predictor: {predictor_keys} ä¸ªå¼ é‡")

if 'target_encoder' in checkpoint:

target_encoder_keys = len(checkpoint['target_encoder'])

print(f" target_encoder: {target_encoder_keys} ä¸ªå¼ é‡")

# è®¡ç®—æ€»å‚æ•°é‡

total_params = 0

for key in ['encoder', 'predictor', 'target_encoder']:

if key in checkpoint:

total_params += sum(p.numel() for p in checkpoint[key].values())

print(f" æ€»å‚æ•°é‡: {total_params:,}")

else:

# å•ä¸€state_dictæ ¼å¼

print("âœ“ æ£€æµ‹åˆ°å•ä¸€state_dictæ ¼å¼")

if isinstance(checkpoint, dict):

state_dict = checkpoint

print(f"æ¨¡å‹åŒ…å« {len(state_dict)} ä¸ªå‚æ•°å¼ é‡")

print(f"æ€»å‚æ•°é‡: {sum(p.numel() for p in state_dict.values()):,}")

# æ˜¾ç¤ºä¸€äº›å…³é”®ä¿¡æ¯

print("\næ¨¡å‹ç»“æ„æ¦‚è§ˆ:")

for i, (name, tensor) in enumerate(state_dict.items()):

if i < 10: # æ˜¾ç¤ºå‰10ä¸ª

print(f" {name}: {tensor.shape}")

elif i == 10:

print(f" ... è¿˜æœ‰ {len(state_dict) - 10} ä¸ªå¼ é‡")

break

# æ£€æŸ¥å¸¸è§çš„å±‚

key_patterns = ['patch_embed', 'pos_embed', 'blocks', 'norm', 'head']

print("\nå±‚ç±»å‹åˆ†æ:")

for pattern in key_patterns:

matching_keys = [k for k in state_dict.keys() if pattern in k.lower()]

if matching_keys:

print(f" {pattern}: {len(matching_keys)} ä¸ªç›¸å…³é”®")

return True

except Exception as e:

print(f"éªŒè¯å¤±è´¥: {e}")

return False

  

def download_via_transformers(model_name="facebook/vjepa2-vitl-fpc64-256", output_dir="./models"):

"""

é€šè¿‡ transformers åº“ä¸‹è½½ V-JEPA 2 æ¨¡å‹

"""

print(f"é€šè¿‡ transformers ä¸‹è½½ {model_name}...")

try:

from transformers import AutoModel, AutoConfig

import torch

# ä¸‹è½½é…ç½®å’Œæ¨¡å‹

config = AutoConfig.from_pretrained(model_name)

model = AutoModel.from_pretrained(model_name)

# ä¿å­˜æ¨¡å‹

Path(output_dir).mkdir(exist_ok=True)

output_path = os.path.join(output_dir, "vjepa2_model.pt")

torch.save(model.state_dict(), output_path)

# ä¿å­˜é…ç½®

config_path = os.path.join(output_dir, "config.json")

config.save_pretrained(output_dir)

print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")

print(f"é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

return output_path

except Exception as e:

print(f"transformers ä¸‹è½½å¤±è´¥: {e}")

return None

  

def download_via_torch_hub(model_name='vjepa2_vit_large', output_dir="./models"):

"""

é€šè¿‡ torch.hub ä¸‹è½½ V-JEPA 2 æ¨¡å‹

"""

print(f"é€šè¿‡ torch.hub ä¸‹è½½ {model_name}...")

try:

import torch

# ä¸‹è½½æ¨¡å‹

model = torch.hub.load('facebookresearch/vjepa2', model_name, pretrained=True)

# ä¿å­˜æ¨¡å‹çŠ¶æ€å­—å…¸

Path(output_dir).mkdir(exist_ok=True)

output_path = os.path.join(output_dir, f"{model_name}.pt")

torch.save(model.state_dict(), output_path)

print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {output_path}")

return output_path

except Exception as e:

print(f"torch.hub ä¸‹è½½å¤±è´¥: {e}")

return None

  

def main():

"""

ä¸»å‡½æ•°

"""

print("V-JEPA 2 æ¨¡å‹ä¸‹è½½è½¬æ¢å·¥å…·ï¼ˆæ”¹è¿›ç‰ˆï¼‰")

print("=" * 60)

# åˆ›å»ºç›®å½•

setup_directories()

# æ–¹æ³•1: å°è¯•é€šè¿‡ transformers ä¸‹è½½

print("æ–¹æ³•1: é€šè¿‡ transformers ä¸‹è½½...")

model_path = download_via_transformers()

if not model_path:

# æ–¹æ³•2: å°è¯•ä» Hugging Face Hub ä¸‹è½½

print("\næ–¹æ³•2: ä» Hugging Face Hub ä¸‹è½½...")

model_path = download_vjepa_from_hf()

if not model_path:

# æ–¹æ³•3: å°è¯•é€šè¿‡ torch.hub ä¸‹è½½

print("\næ–¹æ³•3: é€šè¿‡ torch.hub ä¸‹è½½...")

model_path = download_via_torch_hub()

if model_path:

print(f"\næˆåŠŸä¸‹è½½æ¨¡å‹åˆ°: {model_path}")

# é¦–å…ˆè½¬æ¢ä¸ºå®˜æ–¹æ ¼å¼ï¼ˆä¸»è¦ç›®æ ‡ï¼‰

print("\n--- è½¬æ¢ä¸ºå®˜æ–¹checkpointæ ¼å¼ ---")

converted_path = convert_model_format(model_path, "./converted_models", "official_format")

if converted_path:

if verify_model(converted_path):

print(f"ğŸ‰ å®˜æ–¹æ ¼å¼è½¬æ¢æˆåŠŸ: {converted_path}")

print("âœ… æ¨¡å‹å·²è½¬æ¢ä¸ºå’Œå®˜æ–¹vitg-384.ptç›¸åŒçš„æ ¼å¼!")

else:

print("âŒ å®˜æ–¹æ ¼å¼éªŒè¯å¤±è´¥")

else:

print("âŒ å®˜æ–¹æ ¼å¼è½¬æ¢å¤±è´¥")

else:

print("\nâŒ æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥")

print("\nå¤‡é€‰æ–¹æ¡ˆ:")

print("1. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶")

print("2. ä½¿ç”¨ convert_local_model() å‡½æ•°è½¬æ¢æœ¬åœ°æ–‡ä»¶")

  

def convert_local_model(local_file_path, conversion_mode="official_format"):

"""

è½¬æ¢æœ¬åœ°æ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒå¤šç§è½¬æ¢æ¨¡å¼ï¼‰

"""

if not os.path.exists(local_file_path):

print(f"æ–‡ä»¶ä¸å­˜åœ¨: {local_file_path}")

return None

setup_directories()

return convert_model_format(local_file_path, "./converted_models", conversion_mode)

  

def batch_convert_local_model(local_file_path):

"""

æ‰¹é‡è½¬æ¢æœ¬åœ°æ¨¡å‹æ–‡ä»¶ä¸ºæ‰€æœ‰æ”¯æŒçš„æ ¼å¼

"""

conversion_modes = ["official_format", "encoder_only", "full_model", "backbone_only", "standard_vit", "raw"]

results = {}

for mode in conversion_modes:

print(f"\n--- è½¬æ¢æ¨¡å¼: {mode} ---")

result = convert_local_model(local_file_path, mode)

results[mode] = result

if result and verify_model(result):

print(f"âœ… {mode} æ¨¡å¼è½¬æ¢æˆåŠŸ")

else:

print(f"âŒ {mode} æ¨¡å¼è½¬æ¢å¤±è´¥")

return results

  

if __name__ == "__main__":

# å¯ä»¥ç›´æ¥è¿è¡Œä¸»ç¨‹åº

# main()

# æˆ–è€…è½¬æ¢æœ¬åœ°æ–‡ä»¶ï¼ˆå–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹è·¯å¾„ï¼‰

# convert_local_model("path/to/your/model.pt", "official_format")

# æˆ–è€…æ‰¹é‡è½¬æ¢æ‰€æœ‰æ ¼å¼

# batch_convert_local_model("path/to/your/model.pt")

# æ˜¾ç¤ºä½¿ç”¨è¯´æ˜

print("ğŸ¯ V-JEPAæ¨¡å‹ä¸‹è½½è½¬æ¢å·¥å…·")

print("="*50)

print("ä¸»è¦åŠŸèƒ½: ä¸‹è½½å¹¶è½¬æ¢ä¸ºå®˜æ–¹checkpointæ ¼å¼")

print("\nğŸ“– ä½¿ç”¨è¯´æ˜:")

print("1. main() - ä¸‹è½½å¹¶è½¬æ¢ä¸ºå®˜æ–¹æ ¼å¼")

print("2. convert_local_model(file_path) - è½¬æ¢æœ¬åœ°æ–‡ä»¶ä¸ºå®˜æ–¹æ ¼å¼")

print("3. convert_local_model(file_path, mode) - è½¬æ¢ä¸ºæŒ‡å®šæ ¼å¼")

print("4. batch_convert_local_model(file_path) - æ‰¹é‡è½¬æ¢æ‰€æœ‰æ ¼å¼")

print("\nğŸ”§ è½¬æ¢æ¨¡å¼:")

print("- official_format: è½¬æ¢ä¸ºå®˜æ–¹checkpointæ ¼å¼ (ğŸ¯æ¨è)")

print("- encoder_only: åªæå–encoderéƒ¨åˆ†")

print("- full_model: æå–encoder+predictor")

print("- backbone_only: åªæå–backboneï¼ˆæ— é¢„æµ‹å¤´ï¼‰")

print("- standard_vit: è½¬æ¢ä¸ºæ ‡å‡†ViTæ ¼å¼")

print("- raw: ä¿æŒåŸå§‹æ ¼å¼ï¼Œåªå»é™¤moduleå‰ç¼€")

print("\nğŸ’¡ å¿«é€Ÿå¼€å§‹:")

print('# ä¸‹è½½å¹¶è½¬æ¢ä¸ºå®˜æ–¹æ ¼å¼')

print('main()')

print('\n# è½¬æ¢æœ¬åœ°æ–‡ä»¶')

print('convert_local_model("your_model.pt")')

# è‡ªåŠ¨è¿è¡Œä¸»ç¨‹åº

main()

```

å¾—åˆ°vitl.ptå¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„åï¼Œä½¿ç”¨ `python -m evals.main --fname /root/autodl-tmp/configs/eval/vitl/ssv2.yaml \ --devices cuda:0` æŒ‡ä»¤å°±å¯ä»¥è·‘èµ·æ¥å•¦

ï¼ˆä½†æ˜¯æœ‰ä¸€è¯´ä¸€ï¼Œæˆ‘è¿™ä¸ªé…ç½®è·‘å¾—ç›¸å½“çš„æ…¢ã€‚æœ€åè·‘äº†å››äº”ä¸ªå°æ—¶è¿˜æ²¡è·‘å®Œï¼Œæˆ‘å°±æ‰‹åŠ¨åœä¸‹äº†ï¼Œå› ä¸ºæˆ‘ç§ŸæœåŠ¡å™¨çš„é¢„ç®—è¿˜æ˜¯æœ‰é™çš„ã€‚ã€‚ï¼‰

  

æ¥ä¸‹æ¥ä¸»è¦ä¼šçœ‹ä¸€ä¸‹å®ç°çš„ä»£ç ï¼Œæš‚æ—¶ä¸æ‰“ç®—ç»§ç»­åšè®­ç»ƒçš„è·‘é€šå•¦ã€‚å¦‚æœæœ‰ä»€ä¹ˆé—®é¢˜æ¬¢è¿è”ç³»æˆ‘è®¨è®º~

---

**æ ‡ç­¾**: #æŠ€æœ¯ç¬”è®° #ä¸–ç•Œæ¨¡å‹
**åˆ†ç±»**: æŠ€æœ¯ç¬”è®°  
**åˆ›å»ºæ—¶é—´**: 2025-07-15 22:47  
**æ›´æ–°æ—¶é—´**: 2025-07-15 22:47
